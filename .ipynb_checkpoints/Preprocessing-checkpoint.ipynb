{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c4d0cb9-6992-4242-b11a-95a754c60c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61cc36d0-1354-4802-8c33-d14996c4dcf7",
   "metadata": {},
   "source": [
    "## Loading in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d67232b-7728-403e-847d-ce9f96cae954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing - ./data/Forex/1H\\GBPUSD_H1.csv\n",
      "Done...\n"
     ]
    }
   ],
   "source": [
    "input_size = 192\n",
    "output_size = 12\n",
    "sample_size = input_size + output_size\n",
    "\n",
    "x_data = [] # Should be lists to append to\n",
    "y_data = []\n",
    "min_max = []\n",
    "\n",
    "\n",
    "for root, dirs, files in os.walk(\"./data/Forex/1H\"): # Loop through the folder structure. Could be simplified if you only have one level.\n",
    "    for file in files:\n",
    "        filepath = os.path.join(root, file)  # More robust way to join paths\n",
    "        print(f\"Processing - {filepath}\")\n",
    "        data = pd.read_csv(filepath, header=None, usecols=[1,2,3,4,5], dtype=float, delimiter=\",\")\n",
    "        \n",
    "    # EMA - Exponential Moving Average - 10, 20, 50, 100, 200 - Cols [6,7,8,9,10]\n",
    "        EMA_values = [10,20,50,100]\n",
    "        for periods in EMA_values:\n",
    "            col = len(data.T)\n",
    "            col += 1\n",
    "            data[col] = np.nan\n",
    "            periods = periods - 1\n",
    "            \n",
    "            #First SMA\n",
    "            data.loc[periods, col] =  np.average(data[:periods][4]) # Calculating first simple moving average\n",
    "    \n",
    "            #Then EMA\n",
    "            smoothing_f = 2 / (periods + 1) # smoothing factor\n",
    "            data[col] =  data[4].ewm(span=periods, adjust=False).mean()\n",
    "\n",
    "        \n",
    "    # RSI - Relative Strength Index - Col 11\n",
    "        delta = data[4].diff()  # Calculate price differences\n",
    "        # Separate gains and losses\n",
    "        gain = delta.where(delta > 0, 0)\n",
    "        loss = -delta.where(delta < 0, 0)  # Negate losses to make them positive\n",
    "        \n",
    "        # Calculate average gains and losses using the ewma function\n",
    "        avg_gain = gain.ewm(com=14 - 1, adjust=False).mean()\n",
    "        avg_loss = loss.ewm(com=14 - 1, adjust=False).mean()\n",
    "    \n",
    "        rs = avg_gain / avg_loss  # Calculate the relative strength (RS)\n",
    "        data[11] = 100 - (100 / (1 + rs))  # Calculate the RSI\n",
    "        \n",
    "    # Bollinger Bands - Cols [12,13,14]\n",
    "        # rolling_mean = data[4].rolling(window=20).mean()\n",
    "        # rolling_std = data[4].rolling(window=20).std()\n",
    "    \n",
    "        # # Calculate upper and lower bands\n",
    "        # upper_band = rolling_mean + 2 * rolling_std\n",
    "        # lower_band = rolling_mean - 2 * rolling_std\n",
    "    \n",
    "        # # Add bands to DataFrame\n",
    "        # data[12] = rolling_mean\n",
    "        # data[13] = upper_band\n",
    "        # data[14] = lower_band\n",
    "\n",
    "    # MACD - Moving Average Convergence Divergence - Cols [15,16,17]\n",
    "        # short_ema = data[4].ewm(span=12, adjust=False).mean()\n",
    "        # long_ema = data[4].ewm(span=26, adjust=False).mean()\n",
    "    \n",
    "        # # Calculate MACD line\n",
    "        # macd_line = short_ema - long_ema\n",
    "    \n",
    "        # # Calculate Signal line\n",
    "        # signal_line = macd_line.ewm(span=9, adjust=False).mean()\n",
    "    \n",
    "        # # Calculate MACD histogram\n",
    "        # macd_histogram = macd_line - signal_line\n",
    "    \n",
    "        # # Add to DataFrame\n",
    "        # data[15] = macd_line\n",
    "        # data[16] = signal_line\n",
    "        # data[17] = macd_histogram\n",
    "\n",
    "    # Stochastic Oscillator - Cols [18,19]\n",
    "            # Calculate rolling min and max\n",
    "        low_min = data[4].rolling(window=14).min()\n",
    "        high_max  = data[4].rolling(window=14).max()\n",
    "    \n",
    "        # Calculate %K (Stochastic Oscillator)\n",
    "        k_percent = ((data[4] - low_min) / (high_max - low_min)) * 100\n",
    "    \n",
    "    \n",
    "        # Calculate %D (Smoothed Stochastic Oscillator)\n",
    "        d_percent = k_percent.rolling(window=3).mean()\n",
    "    \n",
    "        # Add to DataFrame\n",
    "        data[18] = k_percent\n",
    "        data[19] = d_percent\n",
    "\n",
    "    # ADX - Average Directional Index - Cols [20,21,22] (+ +Di, -Di)\n",
    "\n",
    "        high = data[2] # Or specify column. Assumed you have a high column.\n",
    "        low = data[3]  # Assumed you have a Low column.\n",
    "        close = data[4]\n",
    "\n",
    "        # Calculate True Range (TR)\n",
    "        tr1 = high - low  # Current High minus the current Low\n",
    "        tr2 = np.abs(high - close.shift(1))  # Current High minus the previous Close\n",
    "        tr3 = np.abs(low - close.shift(1))  # Current Low minus the previous Close\n",
    "        true_range = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1, skipna=False) # Takes the maximum of tr1, tr2, and tr3.\n",
    "    \n",
    "    \n",
    "        # Calculate Plus Directional Movement (+DM) and Minus Directional Movement (-DM)\n",
    "        plus_dm = (high - high.shift(1)).clip(lower=0) # Takes positive gains\n",
    "        minus_dm = (low.shift(1) - low).clip(lower=0) # Takes positive losses\n",
    "        \n",
    "        # Smooth True Range (ATR)\n",
    "        atr = true_range.ewm(alpha=1/14, min_periods=14, adjust=False).mean()\n",
    "        \n",
    "        # Smooth +DM and -DM\n",
    "        plus_di = 100 * (plus_dm.ewm(alpha=1/14, min_periods=14, adjust=False).mean() / atr)\n",
    "        minus_di = 100 * (minus_dm.ewm(alpha=1/14, min_periods=14, adjust=False).mean() / atr)\n",
    "        \n",
    "        # Calculate Directional Index (DX)\n",
    "        dx = 100 * np.abs(plus_di - minus_di) / (plus_di + minus_di)\n",
    "        \n",
    "        # Calculate Average Directional Index (ADX)\n",
    "        adx = dx.ewm(alpha=1/14, min_periods=14, adjust=False).mean()\n",
    "        \n",
    "    \n",
    "        # Add to DataFrame\n",
    "        data[20] = adx\n",
    "        # data[21] = plus_di\n",
    "        # data[22] = minus_di\n",
    "\n",
    "    # Split to x, y data\n",
    "        data = data[100:]\n",
    "\n",
    "        for i in range(len(data) - sample_size + 1):\n",
    "            sample = data.iloc[i:i + sample_size].copy()\n",
    "\n",
    "            # Normalize *each sample individually*\n",
    "            sample_min = sample.min()\n",
    "            sample_max = sample.max()\n",
    "            normalized_sample = (sample - sample_min) / (sample_max - sample_min)\n",
    "\n",
    "            x_sample = normalized_sample.iloc[:input_size].values\n",
    "            y_sample = data.iloc[i:i + sample_size, 3].values[-output_size:] # Take values from original data\n",
    "\n",
    "            x_data.append(x_sample) # Append the numpy arrays so type conversion can occur at once outside loops for optimization\n",
    "            y_data.append(y_sample)\n",
    "            \n",
    "# Convert to NumPy arrays after all files are processed\n",
    "print(\"Done...\")\n",
    "# COLS = Open, High, Low, Close, Volume, 10 EMA, 20 EMA, 50 EMA, 100 EMA, 200 EMA, RSI, bb_rolling_mean, bb_upper, bb_lower, macd, signal, macd_histogram, k%, d%, adx, +d, -d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56b1d0e3-657c-4f4f-8352-6ce86efe470e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = np.array(x_data)\n",
    "y_data = np.array(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d56808fc-b027-49e9-95cd-24197b1926a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_data: (99697, 192, 13) y_data: (99697, 12)\n"
     ]
    }
   ],
   "source": [
    "print(f\"x_data: {x_data.shape} y_data: {y_data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a46620c-1d29-4e70-86ba-cbf0b4d98297",
   "metadata": {},
   "source": [
    "## Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0dad0f58-d460-4927-9cc2-098cd2f5c356",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split = 0.8\n",
    "split_index = int(len(x_data) * train_split)\n",
    "\n",
    "# Create a shuffled array of indices\n",
    "indices = np.arange(len(x_data))\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "# Split the indices\n",
    "train_indices = indices[:split_index]\n",
    "test_indices = indices[split_index:]\n",
    "\n",
    "# Use the shuffled indices to split the data\n",
    "x_train = x_data[train_indices]\n",
    "y_train = y_data[train_indices]\n",
    "x_test = x_data[test_indices]\n",
    "y_test = y_data[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebf3719b-210e-4e20-9a09-244824f4f594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train: (79757, 192, 13) y_train:(79757, 12)\n",
      "x_test: (19940, 192, 13)) y_test: (19940, 12)\n"
     ]
    }
   ],
   "source": [
    "print(f\"x_train: {x_train.shape} y_train:{y_train.shape}\")\n",
    "print(f\"x_test: {x_test.shape}) y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f04fb31-ac67-4f52-b174-709511ef77a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Expanded_Normalised_Data.npy', 'wb') as f:\n",
    "    np.save(f,x_train.astype(np.float16))\n",
    "    np.save(f,y_train.astype(np.float16))\n",
    "    np.save(f,x_test.astype(np.float16))\n",
    "    np.save(f,y_test.astype(np.float16))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a645928-d4e9-4685-a071-fea0c2cfef11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
